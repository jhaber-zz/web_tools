# web_tools
This repository hosts useful scripts and functions for web-crawling and web-scraping, using a variety of modules (mostly in Python): BeautifulSoup, requests, selenium, scrapy, and wget (shell). Used to develop a charter school database of 10K+ units identified using federal data sources (CCD, ACS, etc).

For a discussion of how I use these tools in my charter schools research, including comparison of their outputs and success rates, see [my UC Berkeley presentation](http://tinyurl.com/webscraping-ps239t).

For a customized, working Scrapy Cluster repository (which I ultimately used to scrape charter school websites), [see here](https://github.com/URAP-charter/scrapy-cluster); for documentation explaining how to use it, [see here](https://docs.google.com/document/d/1fCG4At19jlcmPOgvQWkv-J-wJNNyqwXOVPN-9EAwzBk/edit?pli=1#heading=h.dvbc6qukgocx).
