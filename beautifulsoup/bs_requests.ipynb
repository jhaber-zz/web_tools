{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = \"../url_scraping/charter_URLs_2016.csv\"\n",
    "file = \"../url_scraping/json.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(str, file_name):\n",
    "    \"\"\"This function writes a string str to a given file name\"\"\"\n",
    "    with open(file_name, \"a\") as text_file:\n",
    "        text_file.write(str)\n",
    "        \n",
    "def read_txt(txt_file):\n",
    "    \"\"\"This function returns a list of all the lines of a file and also the count\n",
    "    of how many lines\"\"\"\n",
    "    links = []\n",
    "    count = 0\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:   \n",
    "            count +=1\n",
    "            links += [line.rstrip()]\n",
    "    return links, count\n",
    "\n",
    "def readtxt(txt_file):\n",
    "    \"\"\"This function returns a list of tuples and the count of lines\n",
    "    each element of a tuple is separeted by tabtab\n",
    "    example abc 123\n",
    "            cdw 234\n",
    "            return [(abc, 123), (cdw, 234)], 2\"\"\"\n",
    "    links = []\n",
    "    count = 0\n",
    "    with open(txt_file) as f:\n",
    "        for line in f:   \n",
    "            elems = line.split(',')\n",
    "            #elem is a tuple (name, link)\n",
    "            elem =  (elems[0].rstrip(), elems[1].rstrip())\n",
    "            count +=1\n",
    "            links += [elem]\n",
    "    return links, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARTAUTHN2\n"
     ]
    }
   ],
   "source": [
    "links, count = readtxt(valid)\n",
    "print(links[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.polk.edu/lakeland-gateway-to-college-high-school/'\n",
    "# credits: parsing team\n",
    "def parse_data(url):\n",
    "    \n",
    "    data  = requests.get(url).text\n",
    "    soup = BeautifulSoup(data, \"lxml\")\n",
    "    hrefs = soup('a')\n",
    "    paragraphs = soup('p')\n",
    "    #only want unique hrefs\n",
    "    links = []\n",
    "    for each in hrefs:\n",
    "        links.append(each.get('href'))\n",
    "    links = set(links)\n",
    "    return links, paragraphs\n",
    "#TESTING\n",
    "links, paragraphs = parse_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/home'}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "urlkey = ['about', 'department', 'home', 'community', 'life', 'curriculum', 'hist', 'phil', 'academics', 'moral', 'focus', 'beliefs', 'program', 'resources', 'mission', 'value', 'core']\n",
    "urlkey = [s.upper() for s in urlkey]\n",
    "#now parse through all of those links based on the key word search,\n",
    "#and get a new list which contains the url's we actually want\n",
    "# credits parsing team\n",
    "def get_final_list(links):\n",
    "    final_list = []\n",
    "    for k in links:\n",
    "        try:\n",
    "            j = k.upper()\n",
    "            for i in range(len(urlkey)):\n",
    "                if isinstance(j, list) and len(j) == 1:\n",
    "                    j = j[0].split(urlkey[i])\n",
    "                elif isinstance(j, list) and len(j) > 1:\n",
    "                    if requests.get(url + k):\n",
    "                        final_list.append(k)\n",
    "                        break\n",
    "                else:\n",
    "                    j = j.split(urlkey[i])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    final_list += ['/home']\n",
    "    for i in range(len(final_list)):\n",
    "        each = final_list[i].upper()\n",
    "        # split with these keywords because we those pages with tag will not likely to give us \n",
    "        # the info we want\n",
    "        k, m, n, o = each.split('FREQ'), each.split('ADMI'), each.split('TRUSTE'), each.split('ALUM')\n",
    "        if len(k) > 1 or len(m) > 1 or len(n) > 1 or len(o) > 1:\n",
    "            final_list[i] = '/home'\n",
    "    final_list = set(final_list)\n",
    "    return final_list\n",
    "\n",
    "# TESTING\n",
    "final_list = get_final_list(links)\n",
    "print(final_list)\n",
    "print(len(final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MISSION',\n",
       " ' VISION ',\n",
       " 'OUR PURPOSE',\n",
       " 'CAUSE',\n",
       " 'OBJECTIVES',\n",
       " 'VISION:',\n",
       " 'MISSION:']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dictionary to for us to store our relevant texts into into \n",
    "#their respective categories\n",
    "school = {'mission' : [], 'curriculum': [], 'philosophy' : [], 'history' : [], 'target' : [], 'resources' : [], 'organizational_factors' : []}\n",
    "#key words for searching\n",
    "k = [str(x) for x in np.arange(1900,2012)]\n",
    "idk = ['advantage']\n",
    "mission = ['mission',' vision ', 'our purpose', 'cause', 'objectives', 'vision:', 'mission:']\n",
    "curriculum = ['curriculum', 'program', 'methods', 'pedagogy', 'approach', 'model',  'academics', 'degree']\n",
    "philosophy = ['philosophy','beliefs', 'principles', 'creed', 'values',  'moral']\n",
    "history = ['history', 'story', 'background', 'founded', 'established'] + k\n",
    "target = ['target','gifted', 'at-risk', 'ethnic background', 'target population', 'target audience']\n",
    "resources = ['resources', 'ESL', 'tutoring', 'after-school programs', 'available resources', 'services', 'opportunities', 'opportunity']\n",
    "orgfactor = ['organizational_factors', 'statistics', 'API', 'environment', 'ratio', 'average', 'female', 'fund', 'community'  ]\n",
    "keywords = [(mission[0], mission), (curriculum[0], curriculum), (philosophy[0], philosophy), (history[0], history), ( target[0],target) , (resources[0], resources), (orgfactor[0], orgfactor) ]\n",
    "\n",
    "#makes all the text in uppercase\n",
    "for i in range(0,len(keywords)):\n",
    "    keywords[i] = (keywords[i][0], [s.upper() for s in keywords[i][1]])\n",
    "keywords[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mapper function to map the text which we parse through into \n",
    "#its relevant category in the dictionary\n",
    "# credits: parsing team\n",
    "def mapper(txt, school):\n",
    "    \n",
    "#     print(txt.upper())\n",
    "    text = txt.upper()\n",
    "    for i in range(len(keywords)):\n",
    "        update_with_keyword(keywords[i], txt, school)\n",
    "        \n",
    "def update_with_keyword(keyword, txt, school):\n",
    "    \"\"\"This functions updates the school dict with txt\n",
    "    keyword = field name, st mission, history, target, etc\"\"\"\n",
    "    text1 = txt.upper()\n",
    "#     print(keyword[1])\n",
    "    for i in range(len(keyword[1])):\n",
    "        if not isinstance(text1, list):\n",
    "            text1 = text1.split(keyword[1][i])\n",
    "        elif len(text1) == 1:\n",
    "            text1 = text1[0].split(keyword[1][i])\n",
    "        if len(text1) > 1:\n",
    "#             print(keyword[0])\n",
    "            school[keyword[0]].append(txt)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_school_dict(final_list, school):\n",
    "    for link in final_list:\n",
    "        q = requests.get(url + link)\n",
    "        k = q.text\n",
    "        s = BeautifulSoup(k, \"lxml\")\n",
    "        j = s.find_all('p')\n",
    "        for lin in j:\n",
    "            k = str(lin)\n",
    "            if lin.get('class') == None and lin.get('a') == None and len(k.split('|')) == 1:\n",
    "                mapper(' ' + lin.get_text(), school)\n",
    "    # remove duplicates values with set\n",
    "    updated_school = dict((k, set(v)) for k, v in school.items())\n",
    "    return updated_school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mission': set(), 'curriculum': set(), 'philosophy': set(), 'history': set(), 'target': set(), 'resources': set(), 'organizational_factors': {' Polk’s Public Safety students put themselves in harm’s way to protect our community.'}}\n"
     ]
    }
   ],
   "source": [
    "updated_school = update_school_dict(final_list, school)\n",
    "print(updated_school)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(updated_school['mission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(file, school):\n",
    "    with open(file, 'wb') as outfile:\n",
    "#         json.dump(school, outfile)\n",
    "        pickle.dump(school, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "def run_master():\n",
    "    \n",
    "    #get the links, count of valid website links\n",
    "    links, count = readtxt(valid)\n",
    "    result = []\n",
    "    #runing on first 3 sites\n",
    "#     to_run = links[0:300]\n",
    "    for url in links:\n",
    "        \n",
    "        \n",
    "        name, link = url[0], url[1]\n",
    "        print(link)\n",
    "#         link = 'https://www.polk.edu/lakeland-gateway-to-college-high-school/'\n",
    "        links, paragraphs = parse_data(link)\n",
    "        final_list = get_final_list(links)\n",
    "        #create a dictionary to for us to store our relevant texts into into \n",
    "        #their respective categories\n",
    "        school = {'school_name': [], 'mission' : [], 'curriculum': [], 'philosophy' : [], 'history' : [], 'target' : [], 'resources' : [], 'organizational_factors' : []}\n",
    "        try:\n",
    "            updated_school = update_school_dict(final_list, school)\n",
    "            updated_school['school_name'] = name\n",
    "#             print(updated_school)\n",
    "            print(str(count)+name)\n",
    "            \n",
    "            result.append(updated_school)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        count +=1\n",
    "#         result[name] =updated_school\n",
    "    save_json(file, result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHARTAUTHN2\n"
     ]
    },
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'CHARTAUTHN2': No schema supplied. Perhaps you meant http://CHARTAUTHN2?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bc6d6381f0ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_master\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-61bcbde01064>\u001b[0m in \u001b[0;36mrun_master\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         link = 'https://www.polk.edu/lakeland-gateway-to-college-high-school/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlinks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparagraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mfinal_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_final_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#create a dictionary to for us to store our relevant texts into into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2ef4e5fe1efc>\u001b[0m in \u001b[0;36mparse_data\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         )\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         )\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'CHARTAUTHN2': No schema supplied. Perhaps you meant http://CHARTAUTHN2?"
     ]
    }
   ],
   "source": [
    "run_master()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
